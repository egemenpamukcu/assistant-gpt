{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import openai\n",
    "from gtts import gTTS\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define parameters for recording\n",
    "duration = 5  # seconds\n",
    "message_file = \"message.wav\"\n",
    "response_file = \"response.wav\"\n",
    "samplerate = 44100\n",
    "channels = 1\n",
    "language = \"en\"\n",
    "\n",
    "messages = []\n",
    "\n",
    "sys_message = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant named Minerva tasked with psychological assistance and therapy for people struggling with mental health issues. You speak as if a friendly and understanding human speaks in a conversation. You also speak concisely and to the point.\"},\n",
    "        ]\n",
    "\n",
    "# sys_message = [\n",
    "#         {\n",
    "#                 \"role\": \"system\", \n",
    "#                 \"content\": \"Your name is Minerva and you're speaking with a close friend who is going through a tough time. You want to provide them with a safe and supportive space to express their thoughts and feelings. Start by asking them how they're doing and what's been on their mind lately. Listen attentively to their response and offer empathy and understanding. Use language that is warm and friendly, and convey a sense of genuine care and concern. Ask open-ended questions to prompt them to explore their thoughts and feelings in more detail, and offer insights or suggestions for how they can work through their struggles. Remember to be patient, supportive, and non-judgmental throughout the conversation, and let your friend know that you're here for them.\"\n",
    "#         }\n",
    "# ]\n",
    "\n",
    "# messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start recording\n",
    "print(\"recording started\")\n",
    "myrecording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=channels)\n",
    "sd.wait()\n",
    "print(\"recording stopped\")\n",
    "\n",
    "# Save recording to file\n",
    "sf.write(message_file, myrecording, samplerate)\n",
    "\n",
    "# transcript recording\n",
    "audio_file= open(message_file, \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "print(transcript['text'])\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": transcript['text']})\n",
    "\n",
    "# feed transcript to ChatGPT and get output\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=sys_message + messages\n",
    ")\n",
    "\n",
    "response_text = response['choices'][0]['message']['content']\n",
    "print(response_text)\n",
    "\n",
    "message = response['choices'][0]['message'].to_dict()\n",
    "messages.append(message)\n",
    "if len(messages) > 12:\n",
    "  messages.pop(0)\n",
    "\n",
    "# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription='2555c2cf67184a3aa0090f6fff7a33ef', region='eastus')\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "# The language of the voice that speaks.\n",
    "speech_config.speech_synthesis_voice_name='en-US-JennyNeural'\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "ssml = f\"\"\"\n",
    "<speak version=\"1.0\" xmlns=\"https://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\" xmlns:mstts=\"https://www.w3.org/2001/mstts\">\n",
    "  <voice name=\"en-US-JennyNeural\" >\n",
    "    <mstts:express-as style=\"chat\" styledegree=\"2\"> \n",
    "        {response_text}\n",
    "    </mstts:express-as>\n",
    "  </voice>\n",
    "</speak>\n",
    "\"\"\"\n",
    "\n",
    "speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbd06056dac190006ee383166c5069ba080953983f9bad5f4c66a8b202ef27af"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
